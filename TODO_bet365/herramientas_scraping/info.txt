Web que habla sobre como programar un scraper para amazon:

https://www.scrapehero.com/tutorial-how-to-scrape-amazon-product-details-using-python-and-selectorlib/

Aqui hablan de cosas a tener en cuenta con lo proxies:
https://www.scrapehero.com/how-to-rotate-proxies-and-ip-addresses-using-python-3/


Resumen:

De aqui se pueden sacar buenos proxies:
https://free-proxy-list.net/
con el fichero get_proxies.py podemos parsearlo

una vez se tienen los proxies, ellos los rotan de esta manera:

import requests
from itertools import cycle
import traceback
proxies = get_proxies()
proxy_pool = cycle(proxies)

url = 'https://httpbin.org/ip'
for i in range(1,11):
    #Get a proxy from the pool
    proxy = next(proxy_pool)
    print("Request #%d"%i)
    try:
        response = requests.get(url,proxies={"http": proxy, "https": proxy})
        print(response.json())
    except:
        #Most free proxies will often get connection errors. You will have retry the entire request using another proxy to work. 
        #We will just skip retries as its beyond the scope of this tutorial and we are only downloading a single url 
        print("Skipping. Connnection error")

Do not rotate IP Address when scraping websites after logging in or using Sessions
The website already knows who you are when you log in, through the session cookies it sets.The servers can easily tell that you are bot when the same session cookie is coming from multiple IP addresses and block you.

the website already knows that this session is using a certain IP and a User-Agent. Rotating these two fields isn't good.

In these situations, it’s better just to use a single IP address and maintain the same request headers for each unique login.

Avoid Using Proxy IP addresses that are in a sequence: Even the simplest anti-scraping plugins can detect that you are a scraper if the requests come from IP addresses that are continuous or belong to the same range like this:

64.233.160.0

64.233.160.1

64.233.160.2

64.233.160.3

If you are using free proxies – automate:  Free proxies tend to die out soon, mostly in days or hours and would expire before the scraping even completes. To prevent that from disrupting your scrapers, write some code that would automatically pick up and refresh the proxy list.

All proxies aren’t the same. There are mainly three types of proxies available in the internet:

	Transparent Proxy – A transparent proxy is a server that sits between your computer and the internet and redirects your requests and responses without modifying them. It sends your real IP address, revealing that you are using a proxy server.

	Anonymous Proxy – An anonymous proxy does not send your real IP address. The HTTP_VIA header is sent with a transparent proxy, which would reveal you are using a proxy server. The website can still see you are using a proxy server, but in the end, it does not really matter as long as the proxy server does not disclose your real IP address. If someone really wants to restrict page access, an anonymous proxy server will be detected and blocked.

	Elite Proxy (best option)– An elite proxy only sends REMOTE_ADDR header while the other headers are empty. It will make you seem like a regular internet user who is not using a proxy at all.


Aqui habla sobre de como rotar los headers
https://www.scrapehero.com/how-to-fake-and-rotate-user-agents-using-python-3/

dice que tienes que entrar con modo incognito a la web que quieres hacer scrape con varios navegadores y ordenadores y copiar los headers reales de las peticiones.
Con ellos te haces una lista y vas escogiendo aleatoriamente

recordatorio: http request to python: https://curl.trillworks.com/



cuando copiemos los headers de nuestro navegador, hay que sbaer que:

'X-Amzn-Trace-Id': 'Root=1-5ee7b614-d1d9a6e8106184eb3d66b108'

Ignore the X-Amzn-Trace-Id as it is not sent by Python Requests, instead generated by Amazon Load Balancer used by HTTPBin.



HOW TO PREVENT WEBSCRAPPING:
https://stackoverflow.com/questions/3161548/how-do-i-prevent-site-scraping

buena canal de youtube:
https://www.youtube.com/c/Octoparsewebscraping/videos